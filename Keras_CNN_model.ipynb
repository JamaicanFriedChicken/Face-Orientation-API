{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_CNN_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "625dJ1p-GYEp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "      As a result of having a bad GPU at the moment, the framework used was Google Colab. The model used is Keras Convolutional Neural Network (CNN). This model classifies between 4 types of image orientations i.e. 0, 90, 180 and 270 degrees. With having around 329 Images in the training dataset and 112 for the validation dataset, we are able to achieve 94.43% after a series of constant training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHhyyDD_H4K7",
        "colab_type": "text"
      },
      "source": [
        "**Loading Google drive to store files and retrieve if necessary.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG36KKjIQBZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'proj/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSfVe0CkIAnd",
        "colab_type": "text"
      },
      "source": [
        "**Importing the necessary libraries required**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyi_0Ft1Rh9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Convolution2D, Activation, Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNSy6idRITNa",
        "colab_type": "text"
      },
      "source": [
        "**Allows user to upload datasets(.zip)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaPdvbb9cac6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "uploaded1 = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73z6sRltIc65",
        "colab_type": "text"
      },
      "source": [
        "**Creates a folder called dataset and unzips both the train_data.zip and validation_data.zip into the folder.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fACUDuapcfvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir dataset\n",
        "!unzip train_data.zip -d dataset/\n",
        "!unzip validation_data.zip -d dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_iY4xUIIvhN",
        "colab_type": "text"
      },
      "source": [
        "**Initialising variables used in the program**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ondBW_gvZ1jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "num_of_train_samples = 329\n",
        "num_of_test_samples = 112"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O9IpGgYI3m9",
        "colab_type": "text"
      },
      "source": [
        "**Keras model's main architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM1b9CVBRsh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), input_shape=(64,64,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(output_dim=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_dim=4, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCT5oaFpJHbt",
        "colab_type": "text"
      },
      "source": [
        "**Compiling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRvbiTlnR7SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer ='adam', loss ='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHgZzDugJLYr",
        "colab_type": "text"
      },
      "source": [
        "**Train_data generator and test_data generator are data augmentors to create more images and preprocess them in order to improve the model's accuracy in respect to variation.**\n",
        "\n",
        "**Training_set and test_set datasets are being preprocessed and normalised by dimensions of 64x64 in order to prevent errors and other factors from affecting the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kArttPfrR7Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "          rescale=1./255,\n",
        "          shear_range=0.2,\n",
        "          zoom_range=0.2,\n",
        "          horizontal_flip=False)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "                directory='dataset/train_data',\n",
        "                target_size=(64, 64),\n",
        "                batch_size=32,\n",
        "                shuffle=False,\n",
        "                class_mode='categorical')\n",
        "\n",
        "test_set= test_datagen.flow_from_directory(\n",
        "                directory='dataset/validation_data',\n",
        "                target_size=(64, 64),\n",
        "                batch_size=32,\n",
        "                shuffle=False,\n",
        "                class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7a8EM2PKBUU",
        "colab_type": "text"
      },
      "source": [
        "**Model begins training of 50 epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhP2EpZxaTOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "           training_set,\n",
        "           steps_per_epoch=num_of_train_samples // batch_size,\n",
        "           epochs=50,\n",
        "           validation_data=test_set,\n",
        "           validation_steps=num_of_test_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLkCT7ZhKYtl",
        "colab_type": "text"
      },
      "source": [
        "**Calculation of the test_steps_per_epoch variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AuzMYuXbBQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_set.samples / batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra0-HfnnKhUJ",
        "colab_type": "text"
      },
      "source": [
        "**Resets the test_set dataset in order to prevent rearranging that's caused by the model, where the prediction is found by the predict_generator function on the test_set data. predicted_classes and class_labels are to obtain the classes in the dataset and the ground truth. **\n",
        "\n",
        "**Prints a confusion matrix to visualise the model's classifications and mistakes as well as outputs a classification report of the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVbCzmOWaSvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set.reset()\n",
        "predictions = model.predict_generator(test_set, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_set.classes\n",
        "class_labels = list(test_set.class_indices.keys()) \n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(true_classes, predicted_classes))\n",
        "print('Classification Report')  \n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2OHjHTGT07",
        "colab_type": "text"
      },
      "source": [
        "**Saves the model and weights of the Keras CNN as .h5 files to export in the API.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioteDAYkTD1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(root_dir + \" myproj_model.h5\")\n",
        "#model.save_weights(root_dir + \"my_model_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}